{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Смотрим на SVM, LR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгенерируем синтетические данные.\n",
    "X, y = make_classification(\n",
    "    n_samples=10000, n_features=10, n_informative=5, n_redundant=3,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅\n",
    "- Обучите метод опорных векторов. \n",
    "- Подберите параметр регуляризации `C`, подбирайте оптимальные гиперпараметры с точки зрения AUC-PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_pr(y_test: np.ndarray, y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Функция нахождения площади под графиком точности-полноты\n",
    "    :param y_test: np.ndarray размера (n_features,) -- вектор правильных ответов\n",
    "    :param y_pred: np.ndarray размера (n_features,) -- вектор ответов модели\n",
    "    :return: площадь под AUC-PRC линией, число\n",
    "    \"\"\"\n",
    "    precision, recall, th = precision_recall_curve(y_test, y_pred)\n",
    "    return auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отмасштабируем данные (функция StandardScaler вычитает из выборки ее среднее значение и делит на стандартное отклонение)\n",
    "scl = StandardScaler()\n",
    "X = scl.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобъем данные на обучающую и тестовую выборки.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "# Разобъем тренировочную выборку на тренировочную и валидационную.\n",
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_best_selection(C_set: np.ndarray, clf: object, X_t: np.ndarray, y_t, X_val: np.ndarray, y_val: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Подбирает шаг C, при котором качество модели на AUC-PR-кривой наибольшее.\n",
    "    Работает перебором элементов массива C_set в модели clf\n",
    "    :param C_set: numpy-массив значений C\n",
    "    :param clf: объект класса, модель МО\n",
    "    :param X_t: массив тренировочных признаков\n",
    "    :param y_t: вектор тренировочных ответов\n",
    "    :param X_val: массив признаков проверочной выборки\n",
    "    :param y_val: правильные ответы проверочной выборки\n",
    "    :return: лучший вещественный параметр C из C_set для данной clf на данных выборках\n",
    "    \"\"\"\n",
    "    auc_p_r = 0\n",
    "    C = 1.0\n",
    "    \n",
    "    for C_i in C_set:\n",
    "        clf.C = C_i\n",
    "        \n",
    "        clf.fit(X_t, y_t)\n",
    "        a_x = clf.predict(X_val)\n",
    "        \n",
    "        precision, recall, th = precision_recall_curve(y_val, a_x)\n",
    "        \n",
    "        auc_precision_recall = auc(recall, precision)\n",
    "        \n",
    "        if auc_precision_recall > auc_p_r:\n",
    "            auc_p_r = auc_precision_recall\n",
    "            C = C_i\n",
    "            \n",
    "    print(\"Подобранный параметр С:\", C)\n",
    "    return C\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбираем лучший шаг для метода опорных векторов. Опытным путем получаем, что лучшие значения находятся на промежутке от 0.0000001 до 1. Выбираем лучший шаг этого промежутка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подобранный параметр С: 0.015076361809045225\n"
     ]
    }
   ],
   "source": [
    "best_c_linearSVC = c_best_selection(np.linspace(0.000001, 1., 200), LinearSVC(), X_train1, y_train1, X_val,  y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ На тестовой части постройте ROC и PR кривые, а также посчитайте AUC-ROC, AUC-PR с точностью до 5 знаков. Сравните AUC-ROC и AUC-PR для вашей модели с этими же метриками для случайного классификатора (который на каждом объекте выдаёт один из двух классов с равными вероятностями)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "clf.C = best_c_linearSVC\n",
    "clf.fit(X_train, y_train)\n",
    "a_x = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, th_pr = precision_recall_curve(y_test, a_x)\n",
    "fpr, tpr, th_roc = roc_curve(y_test, a_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.78467\n",
      "AUC_PR: 0.84715\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC_ROC: %0.5f\" % auc(fpr, tpr))\n",
    "print(\"AUC_PR: %0.5f\"% auc(recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"ROC\")\n",
    "plt.plot([0,1],[0,1], linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "\n",
    "plt.plot(precision, recall, label=\"PR\")\n",
    "plt.plot([1, 0.5],[0,1], linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ \n",
    "- Проделайте все то же самое для логистической регрессии (LR) — обучение, подбор параметра регуляризации (используйте L2-регуляризацию), вычисление всех метрик и построение кривых. \n",
    "- Сравните результаты LR и SVM с точки зрения всех вычисленных критериев качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. логистическая регрессия вычисляется быстрее метода опорных векторов, увеличим количество значений до 1000 и сдвинем границу до 100. В большинстве случаев лучший шаг все равно меньше единицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подобранный параметр С: 0.4004103603603604\n"
     ]
    }
   ],
   "source": [
    "best_c_LR = c_best_selection(np.linspace(0.00001, 100, 1000), LogisticRegression(), X_train1, y_train1, X_val,  y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.78467\n",
      "AUC_PR: 0.84715\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.C = best_c_LR\n",
    "clf.fit(X_train, y_train)\n",
    "a_x = clf.predict(X_test)\n",
    "\n",
    "precision, recall, th_pr = precision_recall_curve(y_test, a_x)\n",
    "fpr, tpr, th_roc = roc_curve(y_test, a_x)\n",
    "\n",
    "print(\"AUC_ROC: %0.5f\" % auc(fpr, tpr))\n",
    "print(\"AUC_PR: %0.5f\"% auc(recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что AUC_ROC и AUC_PR у двух функционалов равны; значит, графики тоже будут одинаковыми"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌 Работаем с признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
    "$$\n",
    "b_i(x) = [f_j(x) = c_i]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ Загрузим данные [UCI Bank Marketing Dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact   \n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone  \\\n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome   \n",
       "0   may         mon       261         1    999         0  nonexistent  \\\n",
       "1   may         mon       149         1    999         0  nonexistent   \n",
       "2   may         mon       226         1    999         0  nonexistent   \n",
       "3   may         mon       151         1    999         0  nonexistent   \n",
       "4   may         mon       307         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "1           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "2           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "3           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "4           1.1          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 1209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 21)"
      ]
     },
     "execution_count": 1210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ \n",
    " - Разделите выборку на обучающую и тестовую в соотношении 3:1. \n",
    " - Зафиксируйте `random_state=777`, используйте `stratify`.\n",
    " - Удалите столбец, который не несет информации для решения задачи. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 1211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим значения вектора ответов на числа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['y'] == 'yes', 'y'] = 0\n",
    "df.loc[df['y'] == 'no', 'y'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 21)"
      ]
     },
     "execution_count": 1213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим столбец duration, т.к. о нем известно, что он зависит от ответа, что помешает нейронной сети выделить более интересные взаимосвязи в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'duration', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ \n",
    "- Закодируйте категориальные признаки с помощью `OrdinalEncoder`. Посчитайте качество (в этом задании будем работать c `AUC-PR`) при применении логистической регрессии. Замерьте время, потребовавшееся на обучение модели (с учетом кодирования признаков).\n",
    "\n",
    "- Почему в данном задании мы выбрали метрикой именно `AUC-PR`, а не, к примеру, `AUC-ROC`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы выбрали AUC_PR, чтобы избежать возможной неправильной оценки классификатора из-за дисбаланса классов: возможно, AUC-ROC выдавала бы неадекватный результат. Используя PR, мы избегаем неправильной оценки из-за возможного дисбаланса и можем лучше настроить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разделим признаки на категориальные и вещественные**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['job', 'marital', 'education', 'default', 'housing',\n",
    "            'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "\n",
    "num = ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',\n",
    "          'cons.conf.idx', 'cons.price.idx', 'euribor3m', 'nr.employed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка к обучению модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. фрагмент кода будет повторяться, создадим функцию создания пайплайна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe(enc, cat, num):\n",
    "    \"\"\"\n",
    "    Функция создает цепь (пайплайн) классов для обработки категориальных\n",
    "    и вещественных признаков\n",
    "    :param enc: инкодер, класс, который кодирует выборки\n",
    "    :param cat: датафрейм, выборка категориальных признаков\n",
    "    :param num: датафрейм, выборка вещественных признаков\n",
    "    :return: data - датафрейм, содержащий выборки num и cat\n",
    "    (выборки отмасштабированы); clf - пайплайн, который кодирует категориальные\n",
    "    признаки и масштабирует вещественные\n",
    "    \"\"\"\n",
    "\n",
    "    #вещественные признаки также отмасштабируем\n",
    "    data = ColumnTransformer([\n",
    "                     ('cat', enc, cat),\n",
    "                     ('num', StandardScaler(), num)\n",
    "                     ])\n",
    "    \n",
    "    #создадим пайплайн с LogisticRegression регрессией и кодировщиком данных\n",
    "    clf = Pipeline(steps=[\n",
    "                   ('enc_and_st_scaler', data),\n",
    "                   ('classifier', LogisticRegression())\n",
    "                   ])\n",
    "    return data, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для кодирования категориальных признаков используем OrdinalEncoder\n",
    "enc = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, clf = pipe(enc, cat, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переходим к обучению "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Демонстрация работы OrdinalEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame({'name': ['n', 'n', 'v', 'm', 'v', 'n']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name\n",
       "0    n\n",
       "1    n\n",
       "2    v\n",
       "3    m\n",
       "4    v\n",
       "5    n"
      ]
     },
     "execution_count": 1221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 1222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit_transform(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='y'),\n",
    "                                    df['y'], test_size = 0.3,\n",
    "                                    random_state=777, stratify=df['y'])\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель и выводим время обучения, качество модели и количество столбцов, чтобы сравнить ее с другими:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение OrdinalEncoder: 0.36785125732421875\n",
      "AUC-PR на OrdinalEncoder = 0.95330\n",
      "Кол-во столбцов 19\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Время на обучение OrdinalEncoder:', time.time()-start_time)\n",
    "print('AUC-PR на OrdinalEncoder = %.5f' % auc_pr(y_test,y_pred))\n",
    "print('Кол-во столбцов', data.fit_transform(X_train).shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-34 {color: black;}#sk-container-id-34 pre{padding: 0;}#sk-container-id-34 div.sk-toggleable {background-color: white;}#sk-container-id-34 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-34 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-34 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-34 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-34 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-34 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-34 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-34 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-34 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-34 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-34 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-34 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-34 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-34 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-34 div.sk-item {position: relative;z-index: 1;}#sk-container-id-34 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-34 div.sk-item::before, #sk-container-id-34 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-34 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-34 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-34 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-34 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-34 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-34 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-34 div.sk-label-container {text-align: center;}#sk-container-id-34 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-34 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-34\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;enc_and_st_scaler&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;, OrdinalEncoder(),\n",
       "                                                  [&#x27;job&#x27;, &#x27;marital&#x27;,\n",
       "                                                   &#x27;education&#x27;, &#x27;default&#x27;,\n",
       "                                                   &#x27;housing&#x27;, &#x27;loan&#x27;, &#x27;contact&#x27;,\n",
       "                                                   &#x27;month&#x27;, &#x27;day_of_week&#x27;,\n",
       "                                                   &#x27;poutcome&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;age&#x27;, &#x27;campaign&#x27;, &#x27;pdays&#x27;,\n",
       "                                                   &#x27;previous&#x27;, &#x27;emp.var.rate&#x27;,\n",
       "                                                   &#x27;cons.conf.idx&#x27;,\n",
       "                                                   &#x27;cons.price.idx&#x27;,\n",
       "                                                   &#x27;euribor3m&#x27;,\n",
       "                                                   &#x27;nr.employed&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-148\" type=\"checkbox\" ><label for=\"sk-estimator-id-148\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;enc_and_st_scaler&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;, OrdinalEncoder(),\n",
       "                                                  [&#x27;job&#x27;, &#x27;marital&#x27;,\n",
       "                                                   &#x27;education&#x27;, &#x27;default&#x27;,\n",
       "                                                   &#x27;housing&#x27;, &#x27;loan&#x27;, &#x27;contact&#x27;,\n",
       "                                                   &#x27;month&#x27;, &#x27;day_of_week&#x27;,\n",
       "                                                   &#x27;poutcome&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;age&#x27;, &#x27;campaign&#x27;, &#x27;pdays&#x27;,\n",
       "                                                   &#x27;previous&#x27;, &#x27;emp.var.rate&#x27;,\n",
       "                                                   &#x27;cons.conf.idx&#x27;,\n",
       "                                                   &#x27;cons.price.idx&#x27;,\n",
       "                                                   &#x27;euribor3m&#x27;,\n",
       "                                                   &#x27;nr.employed&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-149\" type=\"checkbox\" ><label for=\"sk-estimator-id-149\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">enc_and_st_scaler: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;, OrdinalEncoder(),\n",
       "                                 [&#x27;job&#x27;, &#x27;marital&#x27;, &#x27;education&#x27;, &#x27;default&#x27;,\n",
       "                                  &#x27;housing&#x27;, &#x27;loan&#x27;, &#x27;contact&#x27;, &#x27;month&#x27;,\n",
       "                                  &#x27;day_of_week&#x27;, &#x27;poutcome&#x27;]),\n",
       "                                (&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;age&#x27;, &#x27;campaign&#x27;, &#x27;pdays&#x27;, &#x27;previous&#x27;,\n",
       "                                  &#x27;emp.var.rate&#x27;, &#x27;cons.conf.idx&#x27;,\n",
       "                                  &#x27;cons.price.idx&#x27;, &#x27;euribor3m&#x27;,\n",
       "                                  &#x27;nr.employed&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-150\" type=\"checkbox\" ><label for=\"sk-estimator-id-150\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;job&#x27;, &#x27;marital&#x27;, &#x27;education&#x27;, &#x27;default&#x27;, &#x27;housing&#x27;, &#x27;loan&#x27;, &#x27;contact&#x27;, &#x27;month&#x27;, &#x27;day_of_week&#x27;, &#x27;poutcome&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-151\" type=\"checkbox\" ><label for=\"sk-estimator-id-151\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-152\" type=\"checkbox\" ><label for=\"sk-estimator-id-152\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;campaign&#x27;, &#x27;pdays&#x27;, &#x27;previous&#x27;, &#x27;emp.var.rate&#x27;, &#x27;cons.conf.idx&#x27;, &#x27;cons.price.idx&#x27;, &#x27;euribor3m&#x27;, &#x27;nr.employed&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-153\" type=\"checkbox\" ><label for=\"sk-estimator-id-153\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-154\" type=\"checkbox\" ><label for=\"sk-estimator-id-154\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('enc_and_st_scaler',\n",
       "                 ColumnTransformer(transformers=[('cat', OrdinalEncoder(),\n",
       "                                                  ['job', 'marital',\n",
       "                                                   'education', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome']),\n",
       "                                                 ('num', StandardScaler(),\n",
       "                                                  ['age', 'campaign', 'pdays',\n",
       "                                                   'previous', 'emp.var.rate',\n",
       "                                                   'cons.conf.idx',\n",
       "                                                   'cons.price.idx',\n",
       "                                                   'euribor3m',\n",
       "                                                   'nr.employed'])])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 1193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅\n",
    "- Закодируйте все категориальные признаки с помощью one-hot-кодирования. \n",
    "- Обучите логистическую регрессию и посмотрите, как изменилось качество модели (с тем, что было до кодирования). \n",
    "- Измерьте время, потребовавшееся на кодирование категориальных признаков и обучение модели.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job  marital            education  default housing loan   \n",
       "0       56    housemaid  married             basic.4y       no      no   no  \\\n",
       "1       57     services  married          high.school  unknown      no   no   \n",
       "2       37     services  married          high.school       no     yes   no   \n",
       "3       40       admin.  married             basic.6y       no      no   no   \n",
       "4       56     services  married          high.school       no      no  yes   \n",
       "...    ...          ...      ...                  ...      ...     ...  ...   \n",
       "41183   73      retired  married  professional.course       no     yes   no   \n",
       "41184   46  blue-collar  married  professional.course       no      no   no   \n",
       "41185   56      retired  married    university.degree       no     yes   no   \n",
       "41186   44   technician  married  professional.course       no      no   no   \n",
       "41187   74      retired  married  professional.course       no     yes   no   \n",
       "\n",
       "         contact month day_of_week  campaign  pdays  previous     poutcome   \n",
       "0      telephone   may         mon         1    999         0  nonexistent  \\\n",
       "1      telephone   may         mon         1    999         0  nonexistent   \n",
       "2      telephone   may         mon         1    999         0  nonexistent   \n",
       "3      telephone   may         mon         1    999         0  nonexistent   \n",
       "4      telephone   may         mon         1    999         0  nonexistent   \n",
       "...          ...   ...         ...       ...    ...       ...          ...   \n",
       "41183   cellular   nov         fri         1    999         0  nonexistent   \n",
       "41184   cellular   nov         fri         1    999         0  nonexistent   \n",
       "41185   cellular   nov         fri         2    999         0  nonexistent   \n",
       "41186   cellular   nov         fri         1    999         0  nonexistent   \n",
       "41187   cellular   nov         fri         3    999         1      failure   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "0               1.1          93.994          -36.4      4.857       5191.0  1  \n",
       "1               1.1          93.994          -36.4      4.857       5191.0  1  \n",
       "2               1.1          93.994          -36.4      4.857       5191.0  1  \n",
       "3               1.1          93.994          -36.4      4.857       5191.0  1  \n",
       "4               1.1          93.994          -36.4      4.857       5191.0  1  \n",
       "...             ...             ...            ...        ...          ... ..  \n",
       "41183          -1.1          94.767          -50.8      1.028       4963.6  0  \n",
       "41184          -1.1          94.767          -50.8      1.028       4963.6  1  \n",
       "41185          -1.1          94.767          -50.8      1.028       4963.6  1  \n",
       "41186          -1.1          94.767          -50.8      1.028       4963.6  0  \n",
       "41187          -1.1          94.767          -50.8      1.028       4963.6  1  \n",
       "\n",
       "[41188 rows x 20 columns]"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим переменную enc на OneHotEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для кодирования категориальных признаков используем OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "data, clf = pipe(enc, cat, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='y'),\n",
    "                                    df['y'], test_size = 0.3,\n",
    "                                    random_state=777, stratify=df['y'])\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение OHE: 0.6246130466461182\n",
      "AUC-PR на OHE = 0.95339\n",
      "Кол-во столбцов 62\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Время на обучение OHE:', time.time()-start_time)\n",
    "print('AUC-PR на OHE = %.5f' % auc_pr(y_test,y_pred))\n",
    "print('Кол-во столбцов', data.fit_transform(X_train).shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Счетчики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно было заменить, one-hot-кодирование может сильно увеличивать количество признаков, что сказывается на памяти, особенно, если некоторый признак имеет большое количество значений. Эту проблему решает другой способ кодирования категориальных признаков — mean-target encoding (для простоты будем называть это счётчиками). Основная идея в том, что нам важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории. Метод предполагает кодирование категорий средним арифметическим от суммы целевых меток\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ \n",
    "- Закодируйте категориальные переменные с помощью счётчиков:\n",
    "\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}\n",
    "$$\n",
    "\n",
    "- Обучите логистическую регрессию и посмотрите на качество модели на тестовой выборке. \n",
    "- Сравните с предыдущими экспериментами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вещественные признаки также отмасштабируем, категориальные отмасштабируем отдельно\n",
    "data = ColumnTransformer([\n",
    "                     ('cat', 'passthrough', cat),\n",
    "                     ('num', StandardScaler(), num)\n",
    "                     ])\n",
    "\n",
    "\n",
    "#создадим пайплайн с LogisticRegression регрессией и кодировщиком данных \n",
    "clf = Pipeline(steps=[\n",
    "                   ('enc_and_st_scaler', data),\n",
    "                   ('classifier', LogisticRegression())\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Кодирование категориальных признаков, обучение модели и тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение модели: 1.2472310066223145\n",
      "AUC-PR при mean-target encoding = 0.95312\n",
      "Кол-во столбцов  19\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for col in cat:\n",
    "    for categ in list(pd.unique(X_train[col])):\n",
    "        #используем формулу\n",
    "        g_train = X_train[(X_train[col] == categ) & (y_train == 1)].shape[0] / X_train[X_train[col] == categ].shape[0]\n",
    "        X_train.loc[X_train[col] == categ, col] = g_train\n",
    "        \n",
    "        \n",
    "        g_test = X_test[(X_test[col] == categ) & (y_test == 1)].shape[0] / X_test[X_test[col] == categ].shape[0]\n",
    "        X_test.loc[X_test[col] == categ, col] = g_test \n",
    "\n",
    "#обучение, тестировние        \n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Время на обучение модели:', time.time() - start_time)\n",
    "print(\"AUC-PR при mean-target encoding = %.5f\" %  auc_pr(y_test, y_pred))\n",
    "print('Кол-во столбцов ', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅\n",
    "- Реализуйте корректное вычисление счётчиков самым простым способом — добавление шума к значениям . \n",
    "- Снова обучите логистическую регрессию, оцените качество. \n",
    "- Сделайте выводы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Счетчики с отклонением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение модели: 0.3527834415435791\n",
      "AUC-PR при mean-target encoding и шуме= 0.95223\n",
      "Кол-во столбцов  19\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for col in cat:\n",
    "    #добавим шума к категориальным признакам\n",
    "    X_train[col] += np.random.rand(X_train.shape[0]) * np.sign(np.random.rand(X_train.shape[0]) - 0.5) / 10\n",
    "    X_test[col] += np.random.rand(X_test.shape[0]) * np.sign(np.random.rand(X_test.shape[0]) - 0.5) / 10\n",
    "\n",
    "clf = LogisticRegression()\n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Время на обучение модели:', time.time() - start_time)\n",
    "print(\"AUC-PR при mean-target encoding и шуме= %.5f\" %  auc_pr(y_test, y_pred))\n",
    "print('Кол-во столбцов ', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При шуме качество модели уменьшилось. Возможно, формула кодирования не идеальна и может быть оптимизирована. Однако, время обучения модели тоже уменьшилось по сравнению с OHE из-за того, что мы не добавляем новые столбцы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Счетчики со сглаженным отклонением"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Добавьте сглаживание, а затем повторите эксперименты.\n",
    "\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1] + C \\times global\\_mean}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)] + C}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = 'y'), \n",
    "                                                    df['y'], test_size=0.3, random_state=777, stratify = df['y'])\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вещественные признаки также отмасштабируем, категориальные отмасштабируем отдельно\n",
    "date = ColumnTransformer([\n",
    "                     ('cat', 'passthrough', cat),\n",
    "                     ('num', StandardScaler(), num)\n",
    "                     ])\n",
    "\n",
    "\n",
    "#создадим пайплайн с LogisticRegression регрессией и кодировщиком данных \n",
    "clf = Pipeline(steps=[\n",
    "                   ('enc_and_st_scaler', date),\n",
    "                   ('classifier', LogisticRegression())\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение модели: 1.9697792530059814\n",
      "AUC-PR при global mean = 0.95536\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "C = 100\n",
    "\n",
    "for col in cat:\n",
    "    for categ in list(pd.unique(X_train[col])):\n",
    "        g_new = X_train[(X_train[col] == categ) & (y_train == 1)].shape[0]\n",
    "        #добавляем долю объектов положительного класса\n",
    "        g_new += C * (y_train[y_train == 1].shape[0] / X_train.shape[0])\n",
    "        g_new /= X_train[X_train[col] == categ].shape[0] + C\n",
    "        X_train.loc[X_train[col] == categ, col] = g_new\n",
    "\n",
    "        g_new_test = X_test[(X_test[col] == categ) & (y_test == 1)].shape[0]\n",
    "        #добавляем долю объектов положительного класса\n",
    "        g_new_test += C * (y_test[y_test == 1].shape[0] / y_train.shape[0])\n",
    "        g_new_test /= C + X_test[X_test[col] == categ].shape[0]\n",
    "        X_test.loc[X_test[col] == categ, col] = g_new_test \n",
    "        \n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Время на обучение модели:', time.time() - start_time)\n",
    "print(\"AUC-PR при global mean = %.5f\" %  auc_pr(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели возросло и является наивысшим из полученных. Времени н обработку потребовалось немного больше, чем на OHE, из-за вычислительных сложностей формулы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кодируем возраст клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ В данных имеется признак \"возраст клиента\". Сейчас мы интерпретируем его как числовой, что в общем случае для линейной модели может быть неверной гипотезой. Тем не менее, у этого признака есть довольно много уникальных значений (сколько?), поэтому применять к нему one-hot кодирование может оказаться излишним. Попробуйте закодировать возраст с помощью счетчиков. Стало ли лучше?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = 'y'), \n",
    "                                                    df['y'], test_size=0.3, random_state=777, stratify = df['y'])\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во уникальных возрастов 78\n"
     ]
    }
   ],
   "source": [
    "print('Кол-во уникальных возрастов', df['age'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#теперь возраст категориальная переменная\n",
    "cat = ['job', 'marital', 'education', 'default', 'housing',\n",
    "            'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'age']\n",
    "\n",
    "num = ['campaign', 'pdays', 'previous', 'emp.var.rate',\n",
    "          'cons.conf.idx', 'cons.price.idx', 'euribor3m', 'nr.employed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job            object\n",
       "marital        object\n",
       "education      object\n",
       "default        object\n",
       "housing        object\n",
       "loan           object\n",
       "contact        object\n",
       "month          object\n",
       "day_of_week    object\n",
       "poutcome       object\n",
       "age             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 1197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cat].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories [0.9090406107641983, 0.8596896453383843, 0.6918248326909745, 0.7981313369015728, 0.8540131803662626, 0.7969374598955985, 0.8374060398651985, 0.5953837583982936, 0.7532291674220313, 0.8788588799590081, 0.6175100993191145, 0.8207615147255941] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32ma:\\Поступашки ML\\Семинары\\Семинар 3 (2).ipynb Cell 91\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/%D0%9F%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%B0%D1%88%D0%BA%D0%B8%20ML/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%D1%8B/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%203%20%282%29.ipynb#Y145sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         X_test\u001b[39m.\u001b[39mloc[X_test[col] \u001b[39m==\u001b[39m categ, col] \u001b[39m=\u001b[39m g_new_test \n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/%D0%9F%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%B0%D1%88%D0%BA%D0%B8%20ML/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%D1%8B/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%203%20%282%29.ipynb#Y145sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/a%3A/%D0%9F%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%B0%D1%88%D0%BA%D0%B8%20ML/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%D1%8B/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%203%20%282%29.ipynb#Y145sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/%D0%9F%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%B0%D1%88%D0%BA%D0%B8%20ML/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%D1%8B/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%203%20%282%29.ipynb#Y145sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mВремя на обучение модели:\u001b[39m\u001b[39m'\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/%D0%9F%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%B0%D1%88%D0%BA%D0%B8%20ML/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%D1%8B/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%203%20%282%29.ipynb#Y145sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAUC-PR при global mean = \u001b[39m\u001b[39m%.5f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m  auc_pr(y_test, y_pred))\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:514\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    512\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[0;32m    513\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 514\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[0;32m    515\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:827\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    823\u001b[0m     \u001b[39m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m    825\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 827\u001b[0m Xs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(\n\u001b[0;32m    828\u001b[0m     X,\n\u001b[0;32m    829\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    830\u001b[0m     _transform_one,\n\u001b[0;32m    831\u001b[0m     fitted\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    832\u001b[0m     column_as_strings\u001b[39m=\u001b[39;49mfit_dataframe_and_transform_dataframe,\n\u001b[0;32m    833\u001b[0m )\n\u001b[0;32m    834\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m    836\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Xs:\n\u001b[0;32m    837\u001b[0m     \u001b[39m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:681\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    675\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    676\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[0;32m    677\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    678\u001b[0m     )\n\u001b[0;32m    679\u001b[0m )\n\u001b[0;32m    680\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 681\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m    682\u001b[0m         delayed(func)(\n\u001b[0;32m    683\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[0;32m    684\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    685\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    686\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[0;32m    687\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    688\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[0;32m    689\u001b[0m         )\n\u001b[0;32m    690\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    691\u001b[0m     )\n\u001b[0;32m    692\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1854\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1855\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[0;32m   1857\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1784\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1785\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1786\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:940\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m--> 940\u001b[0m     res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m    941\u001b[0m     \u001b[39m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m    942\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1586\u001b[0m, in \u001b[0;36mOrdinalEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1572\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m   1573\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m \u001b[39m    Transform X to ordinal codes.\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1584\u001b[0m \u001b[39m        Transformed input.\u001b[39;00m\n\u001b[0;32m   1585\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1586\u001b[0m     X_int, X_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(\n\u001b[0;32m   1587\u001b[0m         X,\n\u001b[0;32m   1588\u001b[0m         handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[0;32m   1589\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1590\u001b[0m         ignore_category_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_missing_indices,\n\u001b[0;32m   1591\u001b[0m     )\n\u001b[0;32m   1592\u001b[0m     X_trans \u001b[39m=\u001b[39m X_int\u001b[39m.\u001b[39mastype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1594\u001b[0m     \u001b[39mfor\u001b[39;00m cat_idx, missing_idx \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_missing_indices\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:200\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mif\u001b[39;00m handle_unknown \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    196\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    197\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound unknown categories \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m in column \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m during transform\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(diff, i)\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     \u001b[39mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: Found unknown categories [0.9090406107641983, 0.8596896453383843, 0.6918248326909745, 0.7981313369015728, 0.8540131803662626, 0.7969374598955985, 0.8374060398651985, 0.5953837583982936, 0.7532291674220313, 0.8788588799590081, 0.6175100993191145, 0.8207615147255941] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "C = 100\n",
    "\n",
    "for col in cat:\n",
    "    for categ in list(pd.unique(X_train[col])):\n",
    "        g_new = X_train[(X_train[col] == categ) & (y_train == 1)].shape[0]\n",
    "        #добавляем долю объектов положительного класса\n",
    "        g_new += C * (y_train[y_train == 1].shape[0] / X_train.shape[0])\n",
    "        g_new /= X_train[X_train[col] == categ].shape[0] + C\n",
    "        X_train.loc[X_train[col] == categ, col] = g_new\n",
    "\n",
    "        g_new_test = X_test[(X_test[col] == categ) & (y_test == 1)].shape[0]\n",
    "        #добавляем долю объектов положительного класса\n",
    "        g_new_test += C * (y_test[y_test == 1].shape[0] / y_train.shape[0])\n",
    "        g_new_test /= C + X_test[X_test[col] == categ].shape[0]\n",
    "        X_test.loc[X_test[col] == categ, col] = g_new_test \n",
    "        \n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Время на обучение модели:', time.time() - start_time)\n",
    "print(\"AUC-PR при global mean = %.5f\" %  auc_pr(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что кажество модели немного возросло"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кодируем дни недели и месяцы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Можно пойти и в обратную сторону. У нас есть признаки \"месяц и день недели\" для звонка. Попробуйте интерпретировать их как числовые (месяц от 0 до 12, дни недели от 0 до 4). Стало ли лучше в этот раз?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = {'mon' : 0, 'tue' : 1, 'wed' : 2, 'thu' : 3, 'fri' : 4}\n",
    "months = {'may' : 0, 'jun' : 1, 'jul' : 2, 'aug' : 3, 'oct' : 4,\n",
    "          'nov' : 5, 'dec' : 6, 'mar' : 7, 'apr' : 8, 'sep' : 9}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week'] = np.array(map(days.get, df['day_of_week']))\n",
    "df['month'] = np.array(map(months.get, df['month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=object)"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['day_of_week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение модели: 1.6230988502502441\n",
      "AUC-PR при global mean = 0.96050\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "C = 100\n",
    "\n",
    "for col in cat:\n",
    "    for categ in list(pd.unique(X_train[col])):\n",
    "        g_new = X_train[(X_train[col] == categ) & (y_train == 1)].shape[0]\n",
    "        #добавляем долю объектов положительного класса\n",
    "        g_new += C * (y_train[y_train == 1].shape[0] / X_train.shape[0])\n",
    "        g_new /= X_train[X_train[col] == categ].shape[0] + C\n",
    "        X_train.loc[X_train[col] == categ, col] = g_new\n",
    "\n",
    "        g_new_test = X_test[(X_test[col] == categ) & (y_test == 1)].shape[0]\n",
    "        #добавляем долю объектов положительного класса\n",
    "        g_new_test += C * (y_test[y_test == 1].shape[0] / y_train.shape[0])\n",
    "        g_new_test /= C + X_test[X_test[col] == categ].shape[0]\n",
    "        X_test.loc[X_test[col] == categ, col] = g_new_test \n",
    "        \n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Время на обучение модели:', time.time() - start_time)\n",
    "print(\"AUC-PR при global mean = %.5f\" %  auc_pr(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели продолжает расти"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌 Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важной частью процесса построения модели является отбор признаков. На практике многие признаки оказывают малое влияние на модель (при этом их расчёт занимает время) или даже негативно сказываются на качестве модели. Попробуем несколько подходов отбора признаков, оценим, как они влияют на качество модели и сколько времени занимают.\n",
    "\n",
    "Обратимся к тем же данным про банковский телефонный маркетинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "#удалили целевой столбец и неинформативный признак\n",
    "X = df.drop(columns=['duration', 'y'])\n",
    "\n",
    "#обработали столбец таргета\n",
    "df.loc[df['y'] == 'yes', 'y'] = 0\n",
    "df.loc[df['y'] == 'no', 'y'] = 1\n",
    "y = df['y']\n",
    "\n",
    "#разделили выборку на обучающую и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=777, stratify=y)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>383</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>239</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job  marital            education  default housing loan   \n",
       "0       56    housemaid  married             basic.4y       no      no   no  \\\n",
       "1       57     services  married          high.school  unknown      no   no   \n",
       "2       37     services  married          high.school       no     yes   no   \n",
       "3       40       admin.  married             basic.6y       no      no   no   \n",
       "4       56     services  married          high.school       no      no  yes   \n",
       "...    ...          ...      ...                  ...      ...     ...  ...   \n",
       "41183   73      retired  married  professional.course       no     yes   no   \n",
       "41184   46  blue-collar  married  professional.course       no      no   no   \n",
       "41185   56      retired  married    university.degree       no     yes   no   \n",
       "41186   44   technician  married  professional.course       no      no   no   \n",
       "41187   74      retired  married  professional.course       no     yes   no   \n",
       "\n",
       "         contact month day_of_week  duration  campaign  pdays  previous   \n",
       "0      telephone   may         mon       261         1    999         0  \\\n",
       "1      telephone   may         mon       149         1    999         0   \n",
       "2      telephone   may         mon       226         1    999         0   \n",
       "3      telephone   may         mon       151         1    999         0   \n",
       "4      telephone   may         mon       307         1    999         0   \n",
       "...          ...   ...         ...       ...       ...    ...       ...   \n",
       "41183   cellular   nov         fri       334         1    999         0   \n",
       "41184   cellular   nov         fri       383         1    999         0   \n",
       "41185   cellular   nov         fri       189         2    999         0   \n",
       "41186   cellular   nov         fri       442         1    999         0   \n",
       "41187   cellular   nov         fri       239         3    999         1   \n",
       "\n",
       "          poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m   \n",
       "0      nonexistent           1.1          93.994          -36.4      4.857  \\\n",
       "1      nonexistent           1.1          93.994          -36.4      4.857   \n",
       "2      nonexistent           1.1          93.994          -36.4      4.857   \n",
       "3      nonexistent           1.1          93.994          -36.4      4.857   \n",
       "4      nonexistent           1.1          93.994          -36.4      4.857   \n",
       "...            ...           ...             ...            ...        ...   \n",
       "41183  nonexistent          -1.1          94.767          -50.8      1.028   \n",
       "41184  nonexistent          -1.1          94.767          -50.8      1.028   \n",
       "41185  nonexistent          -1.1          94.767          -50.8      1.028   \n",
       "41186  nonexistent          -1.1          94.767          -50.8      1.028   \n",
       "41187      failure          -1.1          94.767          -50.8      1.028   \n",
       "\n",
       "       nr.employed  y  \n",
       "0           5191.0  1  \n",
       "1           5191.0  1  \n",
       "2           5191.0  1  \n",
       "3           5191.0  1  \n",
       "4           5191.0  1  \n",
       "...            ... ..  \n",
       "41183       4963.6  0  \n",
       "41184       4963.6  1  \n",
       "41185       4963.6  1  \n",
       "41186       4963.6  0  \n",
       "41187       4963.6  1  \n",
       "\n",
       "[41188 rows x 21 columns]"
      ]
     },
     "execution_count": 1200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ В данных много категориальных признаков (сейчас давайте интерпретировать возраст как числовой). Давайте закодируем их с помощью one-hot кодирования. Исходные колонки с категориальными признаками можно удалить. Сколько признаков мы получили?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомним как были разделены признаки (на вещественные и категориальные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['job', 'marital', 'education', 'default', 'housing',\n",
    "            'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "\n",
    "num = ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',\n",
    "          'cons.conf.idx', 'cons.price.idx', 'euribor3m', 'nr.employed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закодируем категориальрные признаки с помощью one-hot кодирования\n",
    "\n",
    "**Будем использовать метод get_dummies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для красивого вывода названий столбцов\n",
    "cat_mask = X_train.select_dtypes(include=['object']).columns\n",
    "cat_mask = X_test.select_dtypes(include=['object']).columns\n",
    "\n",
    "#drop_first = True даст k-1 столбцов для столбца с k категориями -> избежим попадения в дамми-трэп\n",
    "X_train = pd.get_dummies(X_train, columns = cat_mask, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns = cat_mask, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28831, 52)"
      ]
     },
     "execution_count": 1202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ В качестве основной модели будем использовать логистическую регрессию, а целевой метрики — `AUC-PR`. Обучите модель и посчитайте качество на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "a_x = clf.predict(X_test)\n",
    "\n",
    "auc_pr_lr_ohe = auc_pr(y_test, a_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_PR = 0.95222\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC_PR = %.5f\" % auc_pr_lr_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Встроенные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы хотим оставить только 40 лучших признаков. Попробуем сделать это несколькими способами.\n",
    "\n",
    "Начнём с отборам признаков с помощью линейной модели. Как известно, веса линейной модели означают вклад каждого признака в предсказание модели, а значит, модуль этого вклада можно интерпретировать как важность признаков. Такой метод отбора называются встроенным или embedded method, так как он заложен в особенности модели.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ \n",
    " - Оставьте 40 признаков с наибольшим модулем соответствующего параметра линейной модели. Обучите модели заново и оцените её качество. Замерьте скорость такого отбора признаков.\n",
    "\n",
    "Изменилось ли качество? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения модели 0.4056065082550049\n",
      "AUC_PR = 0.95200\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "indices = pd.DataFrame(clf.coef_[0], [*range(52)]).sort_values(by=0).tail(40).index\n",
    "\n",
    "x_train = X_train.iloc[:, indices.values]\n",
    "x_test = X_test.iloc[:, indices.values]\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf1.fit(x_train, y_train)\n",
    "a_x = clf1.predict(x_test)\n",
    "\n",
    "auc_pr_lr_fourty = auc_pr(y_test, a_x)\n",
    "\n",
    "print('Время обучения модели', time.time()-start_time)\n",
    "print(\"AUC_PR = %.5f\" % auc_pr_lr_fourty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество немного уменьшилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы предположили, что признаки вносят вклад равномерно, но не учли их масштаба. Если мы умножим один из признаков в 100 раз, то без учёта регуляризации его вес уменьшится в эти же 100 раз. А мы на основе этого отбираем признаки! Давайте сначала отмасштабируем признаки одним из способов, а только потом будем удалять признаки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Отмасшабируем признаки с помощью StandartScaler и OHE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Снова разделим данные**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "#удалили целевой столбец и неинформативный признак\n",
    "X = df.drop(columns=['duration', 'y'])\n",
    "\n",
    "#обработали столбец таргета\n",
    "df.loc[df['y'] == 'yes', 'y'] = 0\n",
    "df.loc[df['y'] == 'no', 'y'] = 1\n",
    "y = df['y']\n",
    "\n",
    "#разделили выборку на обучающую и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=777, stratify=y)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кодирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вещественные признаки отмасштабируем с помощью StandardScaler, категориальные пока не трогаем\n",
    "date = ColumnTransformer([\n",
    "                     ('cat', 'passthrough', cat),\n",
    "                     ('num', StandardScaler(), num)\n",
    "                     ])\n",
    "\n",
    "X_train = pd.DataFrame(date.fit_transform(X_train))\n",
    "X_test = pd.DataFrame(date.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>wed</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.289536</td>\n",
       "      <td>-0.567466</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>-2.213588</td>\n",
       "      <td>2.249459</td>\n",
       "      <td>-1.599578</td>\n",
       "      <td>-1.669748</td>\n",
       "      <td>-2.061837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>failure</td>\n",
       "      <td>-0.958139</td>\n",
       "      <td>-0.567466</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>1.665344</td>\n",
       "      <td>-1.131825</td>\n",
       "      <td>0.477886</td>\n",
       "      <td>0.781528</td>\n",
       "      <td>-1.563255</td>\n",
       "      <td>-2.419431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.62076</td>\n",
       "      <td>-0.203565</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>-0.113695</td>\n",
       "      <td>-0.321482</td>\n",
       "      <td>-0.647481</td>\n",
       "      <td>0.233315</td>\n",
       "      <td>0.399899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>failure</td>\n",
       "      <td>0.570097</td>\n",
       "      <td>-0.567466</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>1.665344</td>\n",
       "      <td>-1.195458</td>\n",
       "      <td>-1.228873</td>\n",
       "      <td>-1.17796</td>\n",
       "      <td>-1.352571</td>\n",
       "      <td>-0.93521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>mon</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.42973</td>\n",
       "      <td>-0.203565</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>0.840802</td>\n",
       "      <td>-0.278273</td>\n",
       "      <td>1.538367</td>\n",
       "      <td>0.719154</td>\n",
       "      <td>0.845855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28826</th>\n",
       "      <td>unknown</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.42973</td>\n",
       "      <td>-0.203565</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>0.840802</td>\n",
       "      <td>-0.278273</td>\n",
       "      <td>1.538367</td>\n",
       "      <td>0.718579</td>\n",
       "      <td>0.845855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28827</th>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.76711</td>\n",
       "      <td>-0.567466</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>0.840802</td>\n",
       "      <td>0.953186</td>\n",
       "      <td>-0.225863</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>0.845855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28828</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.480565</td>\n",
       "      <td>0.160335</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>0.840802</td>\n",
       "      <td>-0.472714</td>\n",
       "      <td>0.593182</td>\n",
       "      <td>0.774991</td>\n",
       "      <td>0.845855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28829</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.761127</td>\n",
       "      <td>-0.567466</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>-1.195458</td>\n",
       "      <td>-1.228873</td>\n",
       "      <td>-1.17796</td>\n",
       "      <td>-1.313427</td>\n",
       "      <td>-0.93521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.57608</td>\n",
       "      <td>-0.203565</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>-1.195458</td>\n",
       "      <td>-1.228873</td>\n",
       "      <td>-1.17796</td>\n",
       "      <td>-1.333575</td>\n",
       "      <td>-0.93521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28831 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1                    2        3    4    5    \n",
       "0            admin.    single          high.school       no   no  yes  \\\n",
       "1            admin.    single    university.degree       no   no   no   \n",
       "2       blue-collar   married             basic.9y  unknown  yes  yes   \n",
       "3          services   married          high.school       no  yes   no   \n",
       "4      entrepreneur  divorced    university.degree       no  yes  yes   \n",
       "...             ...       ...                  ...      ...  ...  ...   \n",
       "28826       unknown   married             basic.4y  unknown  yes   no   \n",
       "28827     housemaid   married  professional.course       no  yes  yes   \n",
       "28828  entrepreneur    single    university.degree       no   no   no   \n",
       "28829  entrepreneur   married             basic.6y       no   no   no   \n",
       "28830   blue-collar    single    university.degree  unknown  yes   no   \n",
       "\n",
       "              6    7    8            9         10        11        12   \n",
       "0       cellular  nov  wed  nonexistent -0.289536 -0.567466  0.196418  \\\n",
       "1      telephone  aug  wed      failure -0.958139 -0.567466  0.196418   \n",
       "2       cellular  nov  fri  nonexistent   1.62076 -0.203565  0.196418   \n",
       "3       cellular  may  thu      failure  0.570097 -0.567466  0.196418   \n",
       "4      telephone  jun  mon  nonexistent   1.42973 -0.203565  0.196418   \n",
       "...          ...  ...  ...          ...       ...       ...       ...   \n",
       "28826  telephone  jun  tue  nonexistent   1.42973 -0.203565  0.196418   \n",
       "28827   cellular  aug  tue  nonexistent  -0.76711 -0.567466  0.196418   \n",
       "28828   cellular  jul  mon  nonexistent -0.480565  0.160335  0.196418   \n",
       "28829   cellular  may  wed  nonexistent  0.761127 -0.567466  0.196418   \n",
       "28830   cellular  may  mon  nonexistent  -0.57608 -0.203565  0.196418   \n",
       "\n",
       "             13        14        15        16        17        18  \n",
       "0     -0.351015 -2.213588  2.249459 -1.599578 -1.669748 -2.061837  \n",
       "1      1.665344 -1.131825  0.477886  0.781528 -1.563255 -2.419431  \n",
       "2     -0.351015 -0.113695 -0.321482 -0.647481  0.233315  0.399899  \n",
       "3      1.665344 -1.195458 -1.228873  -1.17796 -1.352571  -0.93521  \n",
       "4     -0.351015  0.840802 -0.278273  1.538367  0.719154  0.845855  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "28826 -0.351015  0.840802 -0.278273  1.538367  0.718579  0.845855  \n",
       "28827 -0.351015  0.840802  0.953186 -0.225863  0.778445  0.845855  \n",
       "28828 -0.351015  0.840802 -0.472714  0.593182  0.774991  0.845855  \n",
       "28829 -0.351015 -1.195458 -1.228873  -1.17796 -1.313427  -0.93521  \n",
       "28830 -0.351015 -1.195458 -1.228873  -1.17796 -1.333575  -0.93521  \n",
       "\n",
       "[28831 rows x 19 columns]"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "#кодируем категориальные признаки\n",
    "cat_mask = X_train.select_dtypes(include=['object']).columns\n",
    "cat_mask = X_test.select_dtypes(include=['object']).columns\n",
    "\n",
    "#drop_first = True даст k-1 столбцов для столбца с k категориями -> избежим попадения в дамми-трэп\n",
    "X_train = pd.get_dummies(data=X_train, columns=X_train.iloc[:, 0:10].columns, drop_first=True)\n",
    "X_test = pd.get_dummies(data=X_test, columns=X_test.iloc[:, 0:10].columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>0_blue-collar</th>\n",
       "      <th>0_entrepreneur</th>\n",
       "      <th>0_housemaid</th>\n",
       "      <th>0_management</th>\n",
       "      <th>0_retired</th>\n",
       "      <th>0_self-employed</th>\n",
       "      <th>0_services</th>\n",
       "      <th>0_student</th>\n",
       "      <th>0_technician</th>\n",
       "      <th>0_unemployed</th>\n",
       "      <th>0_unknown</th>\n",
       "      <th>1_married</th>\n",
       "      <th>1_single</th>\n",
       "      <th>1_unknown</th>\n",
       "      <th>2_basic.6y</th>\n",
       "      <th>2_basic.9y</th>\n",
       "      <th>2_high.school</th>\n",
       "      <th>2_illiterate</th>\n",
       "      <th>2_professional.course</th>\n",
       "      <th>2_university.degree</th>\n",
       "      <th>2_unknown</th>\n",
       "      <th>3_unknown</th>\n",
       "      <th>3_yes</th>\n",
       "      <th>4_unknown</th>\n",
       "      <th>4_yes</th>\n",
       "      <th>5_unknown</th>\n",
       "      <th>5_yes</th>\n",
       "      <th>6_telephone</th>\n",
       "      <th>7_aug</th>\n",
       "      <th>7_dec</th>\n",
       "      <th>7_jul</th>\n",
       "      <th>7_jun</th>\n",
       "      <th>7_mar</th>\n",
       "      <th>7_may</th>\n",
       "      <th>7_nov</th>\n",
       "      <th>7_oct</th>\n",
       "      <th>7_sep</th>\n",
       "      <th>8_mon</th>\n",
       "      <th>8_thu</th>\n",
       "      <th>8_tue</th>\n",
       "      <th>8_wed</th>\n",
       "      <th>9_nonexistent</th>\n",
       "      <th>9_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.289536</td>\n",
       "      <td>-0.567466</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>-2.213588</td>\n",
       "      <td>2.249459</td>\n",
       "      <td>-1.599578</td>\n",
       "      <td>-1.669748</td>\n",
       "      <td>-2.061837</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.958139</td>\n",
       "      <td>-0.567466</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>1.665344</td>\n",
       "      <td>-1.131825</td>\n",
       "      <td>0.477886</td>\n",
       "      <td>0.781528</td>\n",
       "      <td>-1.563255</td>\n",
       "      <td>-2.419431</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.62076</td>\n",
       "      <td>-0.203565</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>-0.113695</td>\n",
       "      <td>-0.321482</td>\n",
       "      <td>-0.647481</td>\n",
       "      <td>0.233315</td>\n",
       "      <td>0.399899</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.570097</td>\n",
       "      <td>-0.567466</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>1.665344</td>\n",
       "      <td>-1.195458</td>\n",
       "      <td>-1.228873</td>\n",
       "      <td>-1.17796</td>\n",
       "      <td>-1.352571</td>\n",
       "      <td>-0.93521</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.42973</td>\n",
       "      <td>-0.203565</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>0.840802</td>\n",
       "      <td>-0.278273</td>\n",
       "      <td>1.538367</td>\n",
       "      <td>0.719154</td>\n",
       "      <td>0.845855</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28826</th>\n",
       "      <td>1.42973</td>\n",
       "      <td>-0.203565</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>0.840802</td>\n",
       "      <td>-0.278273</td>\n",
       "      <td>1.538367</td>\n",
       "      <td>0.718579</td>\n",
       "      <td>0.845855</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28827</th>\n",
       "      <td>-0.76711</td>\n",
       "      <td>-0.567466</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>0.840802</td>\n",
       "      <td>0.953186</td>\n",
       "      <td>-0.225863</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>0.845855</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28828</th>\n",
       "      <td>-0.480565</td>\n",
       "      <td>0.160335</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>0.840802</td>\n",
       "      <td>-0.472714</td>\n",
       "      <td>0.593182</td>\n",
       "      <td>0.774991</td>\n",
       "      <td>0.845855</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28829</th>\n",
       "      <td>0.761127</td>\n",
       "      <td>-0.567466</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>-1.195458</td>\n",
       "      <td>-1.228873</td>\n",
       "      <td>-1.17796</td>\n",
       "      <td>-1.313427</td>\n",
       "      <td>-0.93521</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>-0.57608</td>\n",
       "      <td>-0.203565</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>-0.351015</td>\n",
       "      <td>-1.195458</td>\n",
       "      <td>-1.228873</td>\n",
       "      <td>-1.17796</td>\n",
       "      <td>-1.333575</td>\n",
       "      <td>-0.93521</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28831 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             10        11        12        13        14        15        16   \n",
       "0     -0.289536 -0.567466  0.196418 -0.351015 -2.213588  2.249459 -1.599578  \\\n",
       "1     -0.958139 -0.567466  0.196418  1.665344 -1.131825  0.477886  0.781528   \n",
       "2       1.62076 -0.203565  0.196418 -0.351015 -0.113695 -0.321482 -0.647481   \n",
       "3      0.570097 -0.567466  0.196418  1.665344 -1.195458 -1.228873  -1.17796   \n",
       "4       1.42973 -0.203565  0.196418 -0.351015  0.840802 -0.278273  1.538367   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "28826   1.42973 -0.203565  0.196418 -0.351015  0.840802 -0.278273  1.538367   \n",
       "28827  -0.76711 -0.567466  0.196418 -0.351015  0.840802  0.953186 -0.225863   \n",
       "28828 -0.480565  0.160335  0.196418 -0.351015  0.840802 -0.472714  0.593182   \n",
       "28829  0.761127 -0.567466  0.196418 -0.351015 -1.195458 -1.228873  -1.17796   \n",
       "28830  -0.57608 -0.203565  0.196418 -0.351015 -1.195458 -1.228873  -1.17796   \n",
       "\n",
       "             17        18  0_blue-collar  0_entrepreneur  0_housemaid   \n",
       "0     -1.669748 -2.061837          False           False        False  \\\n",
       "1     -1.563255 -2.419431          False           False        False   \n",
       "2      0.233315  0.399899           True           False        False   \n",
       "3     -1.352571  -0.93521          False           False        False   \n",
       "4      0.719154  0.845855          False            True        False   \n",
       "...         ...       ...            ...             ...          ...   \n",
       "28826  0.718579  0.845855          False           False        False   \n",
       "28827  0.778445  0.845855          False           False         True   \n",
       "28828  0.774991  0.845855          False            True        False   \n",
       "28829 -1.313427  -0.93521          False            True        False   \n",
       "28830 -1.333575  -0.93521           True           False        False   \n",
       "\n",
       "       0_management  0_retired  0_self-employed  0_services  0_student   \n",
       "0             False      False            False       False      False  \\\n",
       "1             False      False            False       False      False   \n",
       "2             False      False            False       False      False   \n",
       "3             False      False            False        True      False   \n",
       "4             False      False            False       False      False   \n",
       "...             ...        ...              ...         ...        ...   \n",
       "28826         False      False            False       False      False   \n",
       "28827         False      False            False       False      False   \n",
       "28828         False      False            False       False      False   \n",
       "28829         False      False            False       False      False   \n",
       "28830         False      False            False       False      False   \n",
       "\n",
       "       0_technician  0_unemployed  0_unknown  1_married  1_single  1_unknown   \n",
       "0             False         False      False      False      True      False  \\\n",
       "1             False         False      False      False      True      False   \n",
       "2             False         False      False       True     False      False   \n",
       "3             False         False      False       True     False      False   \n",
       "4             False         False      False      False     False      False   \n",
       "...             ...           ...        ...        ...       ...        ...   \n",
       "28826         False         False       True       True     False      False   \n",
       "28827         False         False      False       True     False      False   \n",
       "28828         False         False      False      False      True      False   \n",
       "28829         False         False      False       True     False      False   \n",
       "28830         False         False      False      False      True      False   \n",
       "\n",
       "       2_basic.6y  2_basic.9y  2_high.school  2_illiterate   \n",
       "0           False       False           True         False  \\\n",
       "1           False       False          False         False   \n",
       "2           False        True          False         False   \n",
       "3           False       False           True         False   \n",
       "4           False       False          False         False   \n",
       "...           ...         ...            ...           ...   \n",
       "28826       False       False          False         False   \n",
       "28827       False       False          False         False   \n",
       "28828       False       False          False         False   \n",
       "28829        True       False          False         False   \n",
       "28830       False       False          False         False   \n",
       "\n",
       "       2_professional.course  2_university.degree  2_unknown  3_unknown   \n",
       "0                      False                False      False      False  \\\n",
       "1                      False                 True      False      False   \n",
       "2                      False                False      False       True   \n",
       "3                      False                False      False      False   \n",
       "4                      False                 True      False      False   \n",
       "...                      ...                  ...        ...        ...   \n",
       "28826                  False                False      False       True   \n",
       "28827                   True                False      False      False   \n",
       "28828                  False                 True      False      False   \n",
       "28829                  False                False      False      False   \n",
       "28830                  False                 True      False       True   \n",
       "\n",
       "       3_yes  4_unknown  4_yes  5_unknown  5_yes  6_telephone  7_aug  7_dec   \n",
       "0      False      False  False      False   True        False  False  False  \\\n",
       "1      False      False  False      False  False         True   True  False   \n",
       "2      False      False   True      False   True        False  False  False   \n",
       "3      False      False   True      False  False        False  False  False   \n",
       "4      False      False   True      False   True         True  False  False   \n",
       "...      ...        ...    ...        ...    ...          ...    ...    ...   \n",
       "28826  False      False   True      False  False         True  False  False   \n",
       "28827  False      False   True      False   True        False   True  False   \n",
       "28828  False      False  False      False  False        False  False  False   \n",
       "28829  False      False  False      False  False        False  False  False   \n",
       "28830  False      False   True      False  False        False  False  False   \n",
       "\n",
       "       7_jul  7_jun  7_mar  7_may  7_nov  7_oct  7_sep  8_mon  8_thu  8_tue   \n",
       "0      False  False  False  False   True  False  False  False  False  False  \\\n",
       "1      False  False  False  False  False  False  False  False  False  False   \n",
       "2      False  False  False  False   True  False  False  False  False  False   \n",
       "3      False  False  False   True  False  False  False  False   True  False   \n",
       "4      False   True  False  False  False  False  False   True  False  False   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "28826  False   True  False  False  False  False  False  False  False   True   \n",
       "28827  False  False  False  False  False  False  False  False  False   True   \n",
       "28828   True  False  False  False  False  False  False   True  False  False   \n",
       "28829  False  False  False   True  False  False  False  False  False  False   \n",
       "28830  False  False  False   True  False  False  False   True  False  False   \n",
       "\n",
       "       8_wed  9_nonexistent  9_success  \n",
       "0       True           True      False  \n",
       "1       True          False      False  \n",
       "2      False           True      False  \n",
       "3      False          False      False  \n",
       "4      False           True      False  \n",
       "...      ...            ...        ...  \n",
       "28826  False           True      False  \n",
       "28827  False           True      False  \n",
       "28828  False           True      False  \n",
       "28829   True           True      False  \n",
       "28830  False           True      False  \n",
       "\n",
       "[28831 rows x 52 columns]"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь выберем 40 признаков с наибольшим модулем соответствующего параметра линейной модели. Обучите модель, оценим её качество.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "print(y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-121\" type=\"checkbox\" checked><label for=\"sk-estimator-id-121\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "X_train = X_train.rename(str, axis='columns')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение модели: 0.4017508029937744\n",
      "AUC-PR (40 признаков) = 0.95215\n",
      "indices = Index([16, 26, 13,  5, 47, 48, 45, 20, 29, 18,  0, 28, 11, 17, 24, 33, 25, 10,\n",
      "       12,  3, 39, 31, 14, 35, 32, 34, 27, 15,  1, 44, 19,  2, 46,  9, 30, 42,\n",
      "       43, 40, 36,  4],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "indices = pd.DataFrame(clf.coef_[0], [*range(52)]).sort_values(by=0).tail(40).index\n",
    "\n",
    "x_train = X_train.iloc[:, indices.values]\n",
    "x_test = X_test.iloc[:, indices.values]\n",
    "x_test = x_test.rename(str, axis='columns')\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf1.fit(x_train, y_train)\n",
    "a_x = clf1.predict(x_test)\n",
    "\n",
    "auc_pr_lr_fourty = auc_pr(y_test,a_x)\n",
    "\n",
    "print('Время на обучение модели:', time.time() - start_time)\n",
    "print(\"AUC-PR (40 признаков) = %.5f\" %  auc_pr_lr_fourty)\n",
    "print('indices =', indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество все равно немного ниже обычных значений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ one-hot кодирование возвращает нам единичные признаки-индикаторы. Попробуйте также отскалировать их, как и обычные числовые, и снова выбрать 40 главных по вкладу признаков. Изменился ли их список? Изменится ли качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "#удалили целевой столбец и неинформативный признак\n",
    "X = df.drop(columns=['duration', 'y'])\n",
    "\n",
    "#обработали столбец таргета\n",
    "df.loc[df['y'] == 'yes', 'y'] = 0\n",
    "df.loc[df['y'] == 'no', 'y'] = 1\n",
    "y = df['y']\n",
    "\n",
    "#разделили выборку на обучающую и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=777, stratify=y)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#кодируем категориальные признаки\n",
    "cat_mask = X_train.select_dtypes(include=['object']).columns\n",
    "cat_mask = X_test.select_dtypes(include=['object']).columns\n",
    "\n",
    "#drop_first = True даст k-1 столбцов для столбца с k категориями -> избежим попадения в дамми-трэп\n",
    "X_train = pd.get_dummies(data=X_train, columns=X_train[cat_mask].columns,\n",
    "                          drop_first=True)\n",
    "X_test = pd.get_dummies(data=X_test, columns=X_test[cat_mask].columns,\n",
    "                          drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = X_train.columns\n",
    "date = ColumnTransformer([\n",
    "                     ('num', StandardScaler(), num)\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вещественные признаки отмасштабируем с помощью StandardScaler, категориальные пока не трогаем\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(date.fit_transform(X_train))\n",
    "X_test = pd.DataFrame(date.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-33 {color: black;}#sk-container-id-33 pre{padding: 0;}#sk-container-id-33 div.sk-toggleable {background-color: white;}#sk-container-id-33 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-33 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-33 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-33 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-33 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-33 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-33 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-33 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-33 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-33 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-33 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-33 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-33 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-33 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-33 div.sk-item {position: relative;z-index: 1;}#sk-container-id-33 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-33 div.sk-item::before, #sk-container-id-33 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-33 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-33 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-33 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-33 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-33 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-33 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-33 div.sk-label-container {text-align: center;}#sk-container-id-33 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-33 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-33\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-147\" type=\"checkbox\" checked><label for=\"sk-estimator-id-147\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 1172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "X_train = X_train.rename(str, axis='columns')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение модели: 0.12791991233825684\n",
      "AUC-PR (40 признаков) = 0.95231\n",
      "indices = Index([47, 48,  0, 13, 38, 16, 22, 29, 28, 45, 26, 18, 24, 17, 11, 10, 25, 12,\n",
      "       14, 33, 32, 34, 39, 35, 44, 19,  3, 27, 15, 46,  9, 31,  1, 30, 43,  2,\n",
      "       40, 42, 36,  4],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "indices = pd.DataFrame(clf.coef_[0], [*range(52)]).sort_values(by=0).tail(40).index\n",
    "\n",
    "x_train = X_train.iloc[:, indices.values]\n",
    "x_test = X_test.iloc[:, indices.values]\n",
    "x_test = x_test.rename(str, axis='columns')\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf1.fit(x_train, y_train)\n",
    "a_x = clf1.predict(x_test)\n",
    "\n",
    "auc_pr_lr_fourty = auc_pr(y_test,a_x)\n",
    "\n",
    "print('Время на обучение модели:', time.time() - start_time)\n",
    "print(\"AUC-PR (40 признаков) = %.5f\" %  auc_pr_lr_fourty)\n",
    "print('indices =', indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество возросло относительно модели, обученной на немасштабированных категориальных признаках, но незначительно. Также уменьшилось время обучения модели, что объясняется сравнительной простотой данных одного масштаба."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы фильтрации\n",
    "\n",
    "\n",
    "Давайте отбирать признаки умнее, а именно через подсчёт некоторой функции для каждого признака. На основании значений этой функции будем оставлять наиболее важные признаки. Методы этого семейства называют фильтрующими или  filter methods. \n",
    "\n",
    "В качестве такой функции будем считать t-статистику:\n",
    "\n",
    "$$t(j) = \\frac{|\\mu_+ - \\mu_-|}{\\sqrt{\\frac{n_+ \\sigma^2_+ + n_- \\sigma^2_-}{n_+ + n_-}}},$$\n",
    "\n",
    "где $\\mu$, $\\sigma$, $n$ соответственно среднее, стандартное отклонение и количество объектов каждого из классов.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Оставьте 40 признаков с наибольшим значением $t$ и замерьте качество. Не забудьте замерить скорость отбора признаков в этом случае."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "#удалили целевой столбец и неинформативный признак\n",
    "X = df.drop(columns=['duration', 'y'])\n",
    "\n",
    "#обработали столбец таргета\n",
    "df.loc[df['y'] == 'yes', 'y'] = 0\n",
    "df.loc[df['y'] == 'no', 'y'] = 1\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "#кодируем категориальные признаки\n",
    "cat_mask = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "#drop_first = True даст k-1 столбцов для столбца с k категориями -> избежим попадения в дамми-трэп\n",
    "X = pd.get_dummies(data=X, columns=X[cat_mask].columns,\n",
    "                          drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = X.columns\n",
    "date = ColumnTransformer([\n",
    "                     ('num', StandardScaler(), num)\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вещественные признаки отмасштабируем с помощью StandardScaler, категориальные пока не трогаем\n",
    "\n",
    "\n",
    "X = pd.DataFrame(date.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_t(df) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Функция вычисляет значение t-статистики для каждого признака,\n",
    "    используя разницу положительного и отрицательного класса в количестве\n",
    "    столбцов, стандартном отклонении и среднем арифметическом значений\n",
    "    \n",
    "    :param df: датафрейм, содержащий вектор ответов (т.е. вся выборка)\n",
    "    :return: np.ndarray с n значениями t-статистики для каждого признака,\n",
    "    где n - кол-во признаков \n",
    "    \"\"\"\n",
    "    i = 1\n",
    "    t = []\n",
    "    for column in df:\n",
    "        if i != df.shape[1]:\n",
    "            u0 = df[column][df['y'] == 0].mean()\n",
    "            u1 = df[column][df['y'] == 1].mean()\n",
    "            n0 = df['y'][df['y'] == 0].count()\n",
    "            n1 = df['y'][df['y'] == 1].count()\n",
    "            s0 = df[column][df['y'] == 0].std()\n",
    "            s1 = df[column][df['y'] == 1].std()\n",
    "            t.append(np.abs(u1 - u0) / sqrt((n1 + s1**2 + n0 - s0**2)/(n1+n0)))\n",
    "        i += 1\n",
    "    return np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=777, stratify=y)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение модели: 1.4539196491241455\n",
      "AUC-PR (40 признаков) = 0.95328\n",
      "indices = Index([26, 25, 48, 37, 40, 33, 43, 47, 18, 10, 46, 29, 23,  0, 39, 15, 20, 24,\n",
      "       28, 21,  6,  1,  9, 38, 13, 16, 30, 42, 45,  5, 44, 41, 36, 50,  3,  4,\n",
      "        7, 51,  2,  8],\n",
      "      dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kayle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "indices = pd.DataFrame(find_t(df), [*range(52)]).sort_values(by=0).tail(40).index\n",
    "\n",
    "x_train = X_train.iloc[:, indices.values]\n",
    "x_test = X_test.iloc[:, indices.values]\n",
    "x_test = x_test.rename(str, axis='columns')\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf1.fit(x_train, y_train)\n",
    "a_x = clf1.predict(x_test)\n",
    "\n",
    "auc_pr_lr_fourty = auc_pr(y_test,a_x)\n",
    "\n",
    "print('Время на обучение модели:', time.time() - start_time)\n",
    "print(\"AUC-PR (40 признаков) = %.5f\" %  auc_pr_lr_fourty)\n",
    "print('indices =', indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы-обёртки\n",
    "\n",
    "\n",
    "Третий из рассматриваемых нами методов работает следующим образом: мы исключаем по очереди один из признаков и смотрим, как это влияет на качество. Удаляем признаки таким жадным способом, пока не окажется выполненым некоторое условие (количество признаков или ухудшение качества).\n",
    "\n",
    "\n",
    "✅ Снова оставьте только 40 признаков и оцените качество на тестовой выборке. Сколько времени занял такой отбор признаков?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ПОДГРУЗКА ДАННЫХ\n",
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "#удалили целевой столбец и неинформативный признак\n",
    "X = df.drop(columns=['duration', 'y'])\n",
    "\n",
    "#обработали столбец таргета\n",
    "df.loc[df['y'] == 'yes', 'y'] = 0\n",
    "df.loc[df['y'] == 'no', 'y'] = 1\n",
    "y = df['y']\n",
    "\n",
    "#обучающая и тестовая\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#валидационная\n",
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "#ПРЕОБРАЗОВАНИЕ ЦЕЛЕЛВОЙ ПЕРЕМЕННОЙ \n",
    "y_train = y_train.astype('int')\n",
    "y_train1 = y_train1.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "y_val = y_val.astype('int')\n",
    "\n",
    "#КОДИРОВАНИЕ ДАННЫХ\n",
    "#закодировали категории\n",
    "cat_mask1 = X_train1.select_dtypes(include=['object']).columns\n",
    "cat_mask2 = X_test.select_dtypes(include=['object']).columns\n",
    "cat_mask3 = X_val.select_dtypes(include=['object']).columns\n",
    "\n",
    "#drop_first = True даст k-1 столбцов для столбца с k категориями -> избежим попадения в дамми-трэп\n",
    "X_train1 = pd.get_dummies(X_train1, columns = cat_mask1, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns = cat_mask2, drop_first=True)\n",
    "X_val = pd.get_dummies(X_val, columns = cat_mask3, drop_first=True)\n",
    "columns_ = X_train1.columns\n",
    "\n",
    "#отмасштабируем все!\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train1 = pd.DataFrame(scaler.fit_transform(X_train1))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test))\n",
    "X_val = pd.DataFrame(scaler.transform(X_val))\n",
    "\n",
    "X_train1.columns = columns_\n",
    "X_test.columns = columns_\n",
    "X_val.columns = columns_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Начинаем отбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cover_method(X_tr, X_test, y_tr, y_test):\n",
    "    \"\"\"\n",
    "    Функция считает значения, которые получаются при обучении выборки без\n",
    "    одного из признаков\n",
    "    :param X_tr: датафрейм для обучения модели\n",
    "    :param X_test: датафрейм для проверки предсказаний модели\n",
    "    :param y_tr: вектор правильных ответов для X_tr\n",
    "    :param y_test: вектор правильных ответов для X_test\n",
    "    :return: numpy-массив с n элементами со значениями обучения без каждого\n",
    "    из столбцов, где n - количество столбцов\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for column in X_tr:\n",
    "\n",
    "        clf1 = LogisticRegression()\n",
    "        clf1.fit(X_tr.drop(columns=column), y_tr)\n",
    "        a_x = clf1.predict(X_test.drop(columns=column))\n",
    "\n",
    "        auc_pr_lr_fourty = auc_pr(y_test,a_x)\n",
    "        results.append(auc_pr_lr_fourty)\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение модели: 13.131893873214722\n",
      "AUC-PR (40 признаков) = 0.95388\n",
      "indices = Index([36, 50, 28, 17,  3, 47,  8, 13,  7, 46, 33, 40, 38,  1,  2, 30, 12, 16,\n",
      "       20, 49,  0, 11, 22, 14,  5, 27, 10, 41, 23, 48,  6, 35, 42, 43, 45, 21,\n",
      "       32, 29, 24, 34],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "indices = pd.DataFrame(cover_method(X_train1, X_test, y_train1, y_test),\n",
    "                        [*range(52)]).sort_values(by=0).head(40).index\n",
    "\n",
    "x_train = X_train1.iloc[:, indices.values]\n",
    "x_test = X_test.iloc[:, indices.values]\n",
    "x_test = x_test.rename(str, axis='columns')\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf1.fit(x_train, y_train1)\n",
    "a_x = clf1.predict(x_test)\n",
    "\n",
    "auc_pr_lr_fourty = auc_pr(y_test,a_x)\n",
    "\n",
    "print('Время на обучение модели:', time.time() - start_time)\n",
    "print(\"AUC-PR (40 признаков) = %.5f\" %  auc_pr_lr_fourty)\n",
    "print('indices =', indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train1.iloc[:, indices.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Стоит отметить, что с помощью такого метода можно пойти и в обратную сторону. Попробуйте добавлять по одному самому полезному признаку в выборку до тех пор, пока не наберется 40 штук. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ПОДГРУЗКА ДАННЫХ\n",
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "#удалили целевой столбец и неинформативный признак\n",
    "X = df.drop(columns=['duration', 'y'])\n",
    "\n",
    "#обработали столбец таргета\n",
    "df.loc[df['y'] == 'yes', 'y'] = 0\n",
    "df.loc[df['y'] == 'no', 'y'] = 1\n",
    "y = df['y']\n",
    "\n",
    "#обучающая и тестовая\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#валидационная\n",
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "#ПРЕОБРАЗОВАНИЕ ЦЕЛЕЛВОЙ ПЕРЕМЕННОЙ \n",
    "y_train = y_train.astype('int')\n",
    "y_train1 = y_train1.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "y_val = y_val.astype('int')\n",
    "\n",
    "#КОДИРОВАНИЕ ДАННЫХ\n",
    "#закодировали категории\n",
    "cat_mask1 = X_train1.select_dtypes(include=['object']).columns\n",
    "cat_mask2 = X_test.select_dtypes(include=['object']).columns\n",
    "cat_mask3 = X_val.select_dtypes(include=['object']).columns\n",
    "\n",
    "#drop_first = True даст k-1 столбцов для столбца с k категориями -> избежим попадения в дамми-трэп\n",
    "X_train1 = pd.get_dummies(X_train1, columns = cat_mask1, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns = cat_mask2, drop_first=True)\n",
    "X_val = pd.get_dummies(X_val, columns = cat_mask3, drop_first=True)\n",
    "columns_ = X_train1.columns\n",
    "\n",
    "#отмасштабируем все!\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train1 = pd.DataFrame(scaler.fit_transform(X_train1))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test))\n",
    "X_val = pd.DataFrame(scaler.transform(X_val))\n",
    "\n",
    "X_train1.columns = columns_\n",
    "X_test.columns = columns_\n",
    "X_val.columns = columns_\n",
    "\n",
    "\n",
    "X_train_3 = pd.DataFrame()\n",
    "X_test_3 = pd.DataFrame()\n",
    "X_valid_3 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отбор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время на обучение модели: 14.24791669845581\n",
      "AUC-PR (40 признаков) = 0.95388\n",
      "indices = [36 50 28 17  3 47  8 13  7 46 33 40 38  1  2 30 12 16 20 49  0 11 22 14\n",
      "  5 27 10 41 23 48  6 35 42 43 45 21 32 29 24 34]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "results = cover_method(X_train1, X_test, y_train1, y_test)\n",
    "\n",
    "n = 40\n",
    "res = []\n",
    "results1 = np.copy(results)\n",
    "results1 = np.argsort(results1)\n",
    "\n",
    "for i in range(n):\n",
    "    res.append(results1[i])\n",
    "res = np.array(res)\n",
    "\n",
    "indices = pd.DataFrame(res, [*range(n)]).values.reshape([-1])\n",
    "x_train = X_train1.iloc[:, indices]\n",
    "x_test = X_test.iloc[:, indices]\n",
    "x_test = x_test.rename(str, axis='columns')\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf1.fit(x_train, y_train1)\n",
    "a_x = clf1.predict(x_test)\n",
    "\n",
    "auc_pr_lr_fourty = auc_pr(y_test,a_x)\n",
    "\n",
    "print('Время на обучение модели:', time.time() - start_time)\n",
    "print(\"AUC-PR (40 признаков) = %.5f\" %  auc_pr_lr_fourty)\n",
    "print('indices =', indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
